import requests
import json
import time
import re
import os
from datasets import load_dataset

# ========================================
# C·∫§U H√åNH
# ========================================
SERVER_URL = "https://myxoid-giftedly-pok.ngrok-free.dev/generate-report"
OUTPUT_GEN_FILE = "generated_reports.jsonl"
OUTPUT_GROUND_TRUTH_FILE = "ground_truth_reports.jsonl"

# 1. Load v√† Split Dataset
huggingface_user = "PLKhang"
dataset_name = "report-finetuning-prompts"

full_dataset = load_dataset(f"{huggingface_user}/{dataset_name}", split="train")
dataset_split = full_dataset.train_test_split(test_size=0.1, seed=42)
test_dataset = dataset_split["test"]

print(f"‚úÖ ƒê√£ chu·∫©n b·ªã {len(test_dataset)} m·∫´u th·ª≠ nghi·ªám.")

# 2. H√†m extract th√¥ng tin an to√†n (Regex linh ho·∫°t)
def extract_info(prompt_text):
    # T√¨m n·ªôi dung gi·ªØa c√°c th·∫ª, ch·∫•p nh·∫≠n m·ªçi bi·∫øn th·ªÉ c·ªßa d·∫•u xu·ªëng d√≤ng
    system = re.search(r"<\|start_header_id\|>system<\|end_header_id\|>\s+(.*?)\s+<\|eot_id\|>", prompt_text, re.DOTALL)
    user = re.search(r"<\|start_header_id\|>user<\|end_header_id\|>\s+(.*?)\s+<\|eot_id\|>", prompt_text, re.DOTALL)
    assistant = re.search(r"<\|start_header_id\|>assistant<\|end_header_id\|>\s+(.*?)\s+<\|eot_id\|>", prompt_text, re.DOTALL)
    
    get_val = lambda m: m.group(1).strip().strip('"') if m else "N/A"
    
    return {
        "system": get_val(system),
        "user": get_val(user),
        "truth": get_val(assistant)
    }

# X√≥a file c≈© n·∫øu c√≥ ƒë·ªÉ ghi m·ªõi t·ª´ ƒë·∫ßu
for f in [OUTPUT_GEN_FILE, OUTPUT_GROUND_TRUTH_FILE]:
    if os.path.exists(f): os.remove(f)

print("üöÄ B·∫Øt ƒë·∫ßu Inference tu·∫ßn t·ª± (Ghi file t·ª©c th√¨)...")

# 3. V√≤ng l·∫∑p Inference v√† Append file
with open(OUTPUT_GEN_FILE, "a", encoding="utf-8") as f_gen, \
     open(OUTPUT_GROUND_TRUTH_FILE, "a", encoding="utf-8") as f_truth:

    for i, item in enumerate(test_dataset):
        info = extract_info(item["prompt"])
        
        payload = {
            "messages": [
                {"role": "system", "content": info["system"]},
                {"role": "user", "content": info["user"]}
            ],
            "max_tokens": 300,
            "temperature": 0.01,
            "top_p": 0.95
        }
        
        try:
            start_time = time.time()
            response = requests.post(SERVER_URL, json=payload, timeout=40) # timeout tr√°nh treo
            res_json = response.json()
            latency = time.time() - start_time
            
            # Ghi d√≤ng k·∫øt qu·∫£ Generator
            gen_data = {
                "id": i,
                "generated_report": res_json.get("report", ""),
                "latency": f"{latency:.2f}s"
            }
            f_gen.write(json.dumps(gen_data, ensure_ascii=False) + "\n")
            f_gen.flush() # √âp ghi xu·ªëng ·ªï ƒëƒ©a ngay l·∫≠p t·ª©c

            # Ghi d√≤ng k·∫øt qu·∫£ Ground Truth
            truth_data = {
                "id": i,
                "input_context": info["user"],
                "expected_report": info["truth"]
            }
            f_truth.write(json.dumps(truth_data, ensure_ascii=False) + "\n")
            f_truth.flush()

            print(f"‚úîÔ∏è [{i+1}/{len(test_dataset)}] - {latency:.2f}s - ƒê√£ l∆∞u")
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫°i m·∫´u {i+1}: {str(e)}")
            continue # Ti·∫øp t·ª•c m·∫´u ti·∫øp theo n·∫øu m·∫´u n√†y l·ªói

print(f"\n‚ú® Ho√†n th√†nh! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u an to√†n t·∫°i {OUTPUT_GEN_FILE} v√† {OUTPUT_GROUND_TRUTH_FILE}")